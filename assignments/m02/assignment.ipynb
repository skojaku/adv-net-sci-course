{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ab1fab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Friendship paradox\n",
    "\n",
    "\"Your friends have more friends than you do\" on average is an interesting phenomenon that highlights a disparity between an individual's perception of their own popularity and the average popularity of their friends. This may seem counterintuitive at first, as we tend to believe that we are just as popular as our friends. However, when we consider from network perspective, it becomes clear why this paradox exists.\n",
    "\n",
    "In this notebook, we will confirm the friendship paradox in a social network. Through this exercise, we will learn how to define and construct a network from non-network data and how to represent it.\n",
    "\n",
    "# Preprocessing\n",
    "## Data are rarely networks\n",
    "\n",
    "Networks appear virtually every corner of the world. But these networks may not explicitly appear in data. As we will see, most data a *collection of observations.* It's your task to define and construct nodes and edges from the collection.\n",
    "\n",
    "Let's see a raw data about social network, i.e., [Copenhagen Network study](https://www.nature.com/articles/s41597-019-0325-x). This study collected data about physical proximities of about 700 students measured based on Bluetooth signals with smartphone. Our dataset is a subset of the original dataset, and I replaced the student IDs with randomly generated names. The original data can be obtained from [here](https://figshare.com/articles/dataset/The_Copenhagen_Networks_Study_interaction_data/7267433/1?file=14000795).\n",
    "\n",
    "Let's glance the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/proximity_data.csv\"\n",
    "contact_data_table = pd.read_csv(filename)\n",
    "contact_data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6f324",
   "metadata": {},
   "source": [
    "***note***: If you are not familiar with `pandas`, you may want to check out [Pandas for Dat aScience in 20 Minutes](https://www.youtube.com/watch?v=tRKeLrwfUgU) for how to use it.\n",
    "\n",
    "While you may have an idea about what the columns represent, I encourage to read the README carefully whenever available. Misunderstanding data format and semantics are a common mistake, and it becomes a disastrous as the analysis moves forward.\n",
    "\n",
    "The README attached to the data is the following:\n",
    "```raw\n",
    "column names:\n",
    "\t- timestamp\n",
    "\t- user A\n",
    "\t- user B\n",
    "\t- received signal strength\n",
    "\n",
    "Notes:\n",
    "Empty scans are marked with user B = -1 and RSSI = 0\n",
    "Scans of devices outside of the experiment are marked with user B = -2. All non-experiment devices are given the same ID.\n",
    "```\n",
    "\n",
    "There are tons of networks that can be created from the same data, and the choice depends on the specific research question. Thus, it is crucial to have a well-thought-out plan in place before touching the data.\n",
    "\n",
    "In this assignment, we want to confirm whether the friendship paradox holds true for the friendship network of the students. Although it is impossible to measure the friendships by the Bluetooth signals, it is natural to expect that friends in the same university would meet frequently in person. Based on the assumption, let's define the friendship network of the students.\n",
    "\n",
    "## Filtering errors and noises\n",
    "The raw data may contain errors, and thus, not all Bluetooth signal data observed accurately represent close physical proximity. Therefore, it is necessary to filter out certain observations. To do so, we must establish clear inclusion criteria to determine what should be considered as in-person interactions.\n",
    "\n",
    "Here, our inclusion criteria are the following\n",
    "1. Bluetooth signals must be stronger than -75dB.\n",
    "2. Focus on the interactions between students who participated in the experiment.\n",
    "3. Ignore the empty scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01417a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Assignment:\n",
    "# Filter out the interactions.\n",
    "#\n",
    "# Hint: pandas.DataFrame.query is a conveient API for filtering rows based on the column values.\n",
    "#\n",
    "# data_table =\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f266f8b",
   "metadata": {},
   "source": [
    "## Data normalization\n",
    "\n",
    "Data normalization is a crucial process that aims to eliminate redundancy, ensure completeness, and maintain consistency in the data. You can think of data normalization as constructing a solid data foundation, which ultimately determines the reliability, accuracy, and efficiency with which a castle (your project) can be built upon it.\n",
    "\n",
    "For network analysis, it is often convenient to create two tables:\n",
    "- *Node table*. This contains metadata about nodes (e.g., timestamp, size, and node IDs)\n",
    "- *Edge table*. This contains metadata about edges (e.g., timestamp, weight, edge type, and edge IDs (optional)).\n",
    "\n",
    "Let's normalize the data step by step.\n",
    "\n",
    "### Normalizing node data\n",
    "\n",
    "It is almost always preferred to assign unique integer IDs to individual nodes in the network.\n",
    "The node table, thus, looks like:\n",
    "\n",
    "| node_id | student_name   |\n",
    "| ------- | -------------- |\n",
    "| 0       | Charlotte Bell |\n",
    "| 1       | Anna Volkova   |\n",
    "| 2       | John Smith     |\n",
    " .....\n",
    "\n",
    "A convenient way to generate unique IDs is to use `numpy.unique` with flag `return_inverse=True`. For instance, consider an array of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Bob\", \"Alice\", \"Bob\", \"James\", \"James\", \"Hana\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b04e73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "With `numpy.unique`, we can generate unique IDs for the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec4ada",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_names, name_ids = np.unique(names, return_inverse=True)\n",
    "unique_names, name_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205360a",
   "metadata": {},
   "source": [
    "where unique names is a list of unique names, and name_ids is a representation of the input array but with integer IDs, instead of the name strings.\n",
    "Don't forget to flag up `return_inverse=True` otherwise you'll get only the unique_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9680599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment:\n",
    "# Create the node table (in pandas DataFrame) with columns, `node_id`, and `student_name`. For example,\n",
    "#\n",
    "# | node_id | student_name   |\n",
    "# | 0       | Charlotte Bell |\n",
    "# | 1       | Anna Volkova   |\n",
    "#  .....\n",
    "#\n",
    "# Hint:\n",
    "# 1. Generate a list of all user names with duplicates\n",
    "# 2. Use `numpy.unique` to generate integer IDs\n",
    "# 3. Create the node_table\n",
    "#\n",
    "# For step 1, you may want to convert pandas.DataFrame to numpy\n",
    "# See https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html\n",
    "\n",
    "# Your code ----\n",
    "\n",
    "\n",
    "# Save the table as pandas.DataFrame and name it `node_table`\n",
    "node_table = pd.DataFrame({\n",
    "    \"node_id\": ...# put a list of node ids here,\n",
    "    \"student_name\": ...# put a list of student names here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "assert all(node_table[\"node_id\"].astype(int) == node_table[\"node_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f195ec",
   "metadata": {},
   "source": [
    "### Normalizing edge data\n",
    "\n",
    "The edge table consists of the following three columns:\n",
    "- `src`: ID of the source node from which an edge emanates\n",
    "- `trg`: ID of the target node to which an edge points\n",
    "- `weight`: (optional) the weight of the edge\n",
    "\n",
    "Data normalization requires you to make some decisions, and it is important to make sure that your decisions are well-aligned with the objective of the analysis.\n",
    "Since our objective is to test the friendship paradox, we want to create a friendship network of students.\n",
    "This means that we need to make a binary decision about whether two students have a friendship or not based on face-to-face interaction data, and this creates an unweighted and undirected network.\n",
    "Here, we *assume* that two persons have a friendship if they interacted more than $\\theta=1$ time.\n",
    "The choice of $\\theta$ values is entirely unconstrained, and you might want to test a different $\\theta$ value to ensure the robustness of the final conclusion.\n",
    "But for a moment, let's take it granted and move forward.\n",
    "\n",
    "So, let's create an edge table. To this end, we will\n",
    "1. count the number of interactions between two individuals, and then\n",
    "2. threshold the interaction by $\\theta=1$ to generate the undirected and unweighted network.\n",
    "\n",
    "One thing to be careful at step 1: the `user_a` and `user_b` are exchangeable, meaning that the following two edges represent the same undirected edge:\n",
    "\n",
    "| user_a | user_b |\n",
    "| ------ | ------ |\n",
    "| 0      | 22     |\n",
    "| 22     | 0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e736228",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%time # This is a magic command to measure the execution time of this cell.\n",
    "# Assignment:\n",
    "# Create a table `edge_table` by pandas DataFrame, which represents the edge table with columns, `src`, `trg`.\n",
    "# For example,\n",
    "#\n",
    "#  | src | trg  |\n",
    "#  | 0   | 1    |\n",
    "#  | 0   | 22   |\n",
    "#  .....\n",
    "#\n",
    "\n",
    "# Your code here ----------\n",
    "\n",
    "\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# Make sure that your edge table passes the following test!\n",
    "# Check if the node IDs are integers\n",
    "assert all(edge_table[\"src\"].astype(int) == edge_table[\"src\"])\n",
    "assert all(edge_table[\"trg\"].astype(int) == edge_table[\"trg\"])\n",
    "\n",
    "\n",
    "# Check if the edge table has no duplicated edges\n",
    "def has_no_duplicated_edges(edge_table):\n",
    "    df = pd.DataFrame(\n",
    "        np.sort(edge_table[[\"src\", \"trg\"]].values, axis=1)\n",
    "    ).drop_duplicates()\n",
    "    return df.shape[0] == edge_table.shape[0]\n",
    "\n",
    "\n",
    "assert has_no_duplicated_edges(edge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28064e",
   "metadata": {},
   "source": [
    "How long did it take to normalize the edge table? The speed is crucial since the normalization can be time-consuming and may become impractical for large networks if not executed efficiently. If you are interested in how to make it efficient, check out [here](https://github.com/skojaku/adv-net-sci-course/wiki/Finding-and-counting-duplicated-edges) for a numerical trick.\n",
    "\n",
    "# Visualization\n",
    "\n",
    "Let's take a break and appreciate your work by transforming the tables into a fun visualization. The visualization not only is fun experience but also serves as a valuable tool for understanding the network structure. With visualization, we can leverage our powerful biological GPUs in brain to gain numerous new insights into the network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56558fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph\n",
    "import numpy as np\n",
    "\n",
    "g = igraph.Graph.DataFrame(edge_table[[\"src\", \"trg\"]], directed=False)\n",
    "igraph.plot(g, vertex_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326a7ac",
   "metadata": {},
   "source": [
    "# From edge table to adjacency matrix\n",
    "\n",
    "While the edge table is simple, it is not a convenient format when it comes to computing. A more convenient format is the **adjacency matrix**. It is a square matrix, where each $(i,j)$ entry represents the presence $A_{ij}=1$ or absence $A_{ij}=0$ of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "# - Create an adjacency matrix (`A` as a numpy 2D array ) from the edge table.\n",
    "# - A[i,j] (and A[j,i]) are the `weight` in the edge table, meaning they represent the number of edges between nodes i and j\n",
    "# - Make sure A[i,j] = A[j,i]\n",
    "\n",
    "src = edge_table[\"src\"].values\n",
    "trg = edge_table[\"trg\"].values\n",
    "# Or you can simply write\n",
    "# > src, trg = tuple(edge_table[[\"src\", \"trg\"]].values.T)\n",
    "\n",
    "n_nodes = node_table.shape[0]\n",
    "A = np.zeros(\n",
    "    (n_nodes, n_nodes)\n",
    ")  # This will create an n_nodes x n_nodes array with all entry values being zero\n",
    "\n",
    "# Write your code from here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a6cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "assert np.all(\n",
    "    A == A.T\n",
    ")  # make sure that A[i,j] = A[j,i] (the adjacency matrix is symmetric)\n",
    "assert np.max(A) == 1\n",
    "assert np.min(A) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2d792",
   "metadata": {},
   "source": [
    "The adjacency matrix is a powerful representation that is convenient for computation.  For example, the number of friends for a node (i.e., degree in network terminology) can be computed by\n",
    "taking a row sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d7db8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "node_id = 1\n",
    "np.sum(A[node_id, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b184f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "and the degrees of all nodes can be computed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = A.sum(\n",
    "    axis=1\n",
    ")  # this will sum the entry values along the column. This will create a 2D array with 1 column.\n",
    "deg = deg.ravel()  # `.ravel` flatten 2D into 1D array.\n",
    "deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292ecaa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Testing the Friendship paradox\n",
    "\n",
    "We are now ready to test the friendship paradox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "# 1. Compute the average number of friends\n",
    "# 2. Compute the average number of friends that individual nodes' friends have\n",
    "# 3. Compare the two values and confirm the friendship paradox\n",
    "#\n",
    "#\n",
    "# Hint:\n",
    "# Create two lists. One list contains the IDs of individual nodes. The other list contains the IDs of each node's friends.\n",
    "# The first list does not contain duplicated IDs. But the second list should have duplicated IDs, since a friend can be a friend of another node.\n",
    "# Then, compute the average degree of the nodes in each list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806126f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Did you confirm the friendship paradox?\n",
    "\n",
    "An interesting fact about the friendship paradox is that it is always true no matter how the nodes are connected unless everyone has exactly the same number of friends.\n",
    "\n",
    "So why does the friendship paradox arise? When we pick a friend of a node, we essentially traverse an edge from the node, and most edges are connected to popular individuals (hubs), since they hold most edges in the network. In other words, popular individuals tend to appear the friend list of many people, and these popular individuals are counted multiple times, when computing the degree of friends, resulting in the friendship paradox.\n",
    "\n",
    "# Efficient representation for sparse networks\n",
    "## Coordinate list and adjacency list\n",
    "\n",
    "While the adjacency matrix is convenient, it is a computationally redundant and expensive representation. Let's take a look at the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the adjacency matrix\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba10341",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As you can see, only few entries have value one, while most entries have zero values. The adjacency matrix is a *redundant* representations; it has $n \\times n$ values, few of which indicates the presence of edges. The number of values increases quadratically and can quickly exceeds the memory.\n",
    "\n",
    "The edge table is in fact an efficient representation, since it keeps only the elements of non-zero values.\n",
    "An edge table is also called *coordinate list*, since the `src`, `trg` can be regarded as a coordinate of non-zero entries of the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52003522",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Another efficient representation is the adjacency list representation. It is a dictionary with keys being nodes. Each value associated with a key is a list of neighbor node IDs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee75aea7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "d = {\n",
    "  0: [6,11,16], # neighbor of nodes 0\n",
    "  1: [3, 16, 21] # neighbors of node 1\n",
    "  ...\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dd72e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This representation is also known as the dictionary of keys (DOK) or list-of-list (LIL).\n",
    "\n",
    "## Compressed sparse row/column\n",
    "\n",
    "![](https://matteding.github.io/images/csr.gif)\n",
    "\n",
    "Compressed Sparse Row (CSR) is a highly efficient representation of a sparse matrix. Its main concept revolves around concatenating the adjacency list. Here's how it works: let's say we have an adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273a928",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "[\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 0, 1, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa136cc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The adjacency list of the matrix is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78297944",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "{\n",
    "    0: [1, 2, 3],  # neighbors of node 0\n",
    "    1: [0, 2],  # neighbors of node 1\n",
    "    2: [0, 1, 3],  # neighbors of node 2\n",
    "    3: [0, 2],  # neighbors of node 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc2f29",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now, let's talk about the CSR matrix.\n",
    "The CSR matrix representation consists of three arrays, i.e., `indices`, `indptr`, and `data`. The `indices` is formed by combining the lists into a single list.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{indices}:=[\\underbrace{1,2,3}_{\\text{node 0}},\\underbrace{0,2}_{\\text{node 1}},\\underbrace{0,1,3}_{\\text{node 2}},\\underbrace{0,2}_{\\text{node 3}}]\n",
    "\\end{align}\n",
    "$$\n",
    "The array `indices` consists of $n=4$ subarrays, with each subarray representing the neighbors of a specific node. Additionally, there is another array called `indptr` that indicates the partitioning of the\n",
    "`indices` array.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{indptr}:=[0,3,5,8,10]\n",
    "\\end{align}\n",
    "$$\n",
    "The `indptr` array indicates the starting indices of each subarray. For example, `indptr[0]` indicates the index from which the neighbors of node 0 are listed, and `indptr[1]` indicates another index from which the neighbors of node 1 is listed.\n",
    "\n",
    "If the sparse matrix is not a binary matrix, meaning the entries of the matrix can take values other than 0 and 1, the CSR representation also includes a `data` array that contains the entry values. The `data` array is divided into subarrays in the same manner as the `indices` array. For example, `data[0]` represents the weight of the edge to the neighbor `indices[0]`.\n",
    "\n",
    "With that, let's create the CSR representation of the network. Let's first create the adjacency list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58735648",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Assignment:\n",
    "# Create the adjacency list (with a dictionary named adjList) of the network of the students and courses.\n",
    "# adjList = {\n",
    "#   0: [...]\n",
    "#   1: [...]\n",
    "#   2: [...]\n",
    "#   ....\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e9b6f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then, create the CSR representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebf46b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Assignment:\n",
    "# Create the CSR representation of the network of the students and courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22552da8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "CSR matrix is useful in finding the neighbors of a specific node, just like the adjacency list. For instance,\n",
    "the neighbors of node 10 is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511cda8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "node_id = 10\n",
    "indices[indptr[node_id] : indptr[node_id + 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b60611",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Why it works? Let's break down the second line.\n",
    "The variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a81181",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a9208",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "is an array consisting of subarrays. And each subarray is associated with a row of the adjacency matrix and consists of column IDs with non-zero entry values for the row.\n",
    "The subarrays are partitioned by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064ef80",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "indptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583bbb2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8518cc5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "indices[indptr[10] : indptr[10 + 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fe9ad",
   "metadata": {},
   "source": [
    "is a subarray associated with the 12th row (and thus node 10), which contains the column IDs of the non-zero entries."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
