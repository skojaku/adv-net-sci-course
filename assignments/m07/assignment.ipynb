{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1164465",
   "metadata": {},
   "source": [
    "# Centrality\n",
    "\n",
    "Centrality is a central metric in network analysis used to determine the importance of a node within a network based on its structural position. It can also be applied to individual edges, measuring the significance of a link within the network. Numerous centrality metrics have been developed, and in this assignment, we will explore some commonly used centrality metrics.\n",
    "\n",
    "#### Network data\n",
    "\n",
    "We will use the worldwide airport network based on data taken from Openflight.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c58fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import igraph\n",
    "import numpy as np\n",
    "\n",
    "node_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/airport_network_v2/node_table.csv\"\n",
    ")\n",
    "edge_table = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/skojaku/adv-net-sci-course/main/data/airport_network_v2/edge_table.csv\"\n",
    ")\n",
    "src, trg = tuple(edge_table[[\"src\", \"trg\"]].values.T)\n",
    "edge_list = tuple(zip(src, trg))\n",
    "\n",
    "# node_id and name dictionary\n",
    "n_nodes = node_table.shape[0]\n",
    "id2name = np.array([\"\"] * n_nodes, dtype=\"<U64\")\n",
    "id2name[node_table[\"node_id\"]] = node_table[\"Name\"].values\n",
    "\n",
    "g = igraph.Graph(\n",
    "    edge_list,\n",
    "    vertex_attrs=dict(Name=id2name, node_id=node_table[\"node_id\"].values),\n",
    ")\n",
    "\n",
    "# You can retrieve the airport names by\n",
    "print(g.vs[0][\"Name\"], \",\", g.vs[1][\"Name\"], \", ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe44b8",
   "metadata": {},
   "source": [
    "## Degree centrality\n",
    "\n",
    "The simplest metric of centrality is degree centrality. The centrality of a node is the degree of the node. And with igraph, you can get the degree of nodes by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = g.degree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ad1ea",
   "metadata": {},
   "source": [
    "## Path-based centrality\n",
    "\n",
    "#### Closeness centrality\n",
    "\n",
    "One way to measure the importance of nodes is to measure how central they are in the network. A node at the center of the network should be able to reach any other nodes in *short* distances. One way to quantify this is to take the sum of the distances from individual nodes to all other nodes in the network, with a simple inversion to make \"central\" nodes having a high centrality, i.e.,\n",
    "$$\n",
    "c_i:= \\frac{n-1}{\\sum_{j, i\\neq j} d(i,j)},\n",
    "$$\n",
    "where $d(i,j)$ is the shortest path length between nodes $i$ and $j$, and $n$ is the number of nodes in the network. This metric is called *closeness centrality*. The numerator serves as a scaling constant to make the metric vary in the range $(0,1]$. With `igraph`, it can be computed by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_centrality = g.closeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc22463",
   "metadata": {},
   "source": [
    "#### Betweenness centrality\n",
    "\n",
    "Betweenness centrality is another widespread centrality based on the shortest path lengths. It is defined by\n",
    "$$\n",
    "b_i:= \\sum_{s \\neq t\\neq i} \\frac{\\sigma_{s,i,t}}{\\sigma_{s,t}}\n",
    "$$\n",
    "where $\\sigma_{s,t}$ is the number of shortest paths between node $s$ and node $v$, and $\\sigma_{s,i,t}$ is the shortest paths between $s$ and $t$ that goes through node $i$. A node with a high betweenness centrality means that the node is a dominant intermediary of flows (that go through the shortest path) between nodes on the network. Or, you can think of it as a bottleneck of flows. With igraph, you can compute the betweenness centrality by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eae847",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality = g.closeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93cf82",
   "metadata": {},
   "source": [
    "The idea of betweenness centrality can be extended to edges. Instead of counting the number of shortest paths going through nodes, we can count them for each edge and define the betweenness centrality in the same way. You can compute the edge betweenness centrality with igraph by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_betweeness_centrality = g.edge_betweenness()  # compute the betweenness centrality\n",
    "\n",
    "# You can retrieve the edge lists pertaining to the edge betweenness centrality by\n",
    "edge_list = g.get_edgelist()\n",
    "\n",
    "# For example, the betweenness centrality edge_betweeness_centrality[10] corresponds to an edge edge_list[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a18ff8",
   "metadata": {},
   "source": [
    "# Robustness\n",
    "\n",
    "Another approach to determining the importance of nodes is by evaluating the impact their removal would have on the network. For instance, an individual can be deemed important within a social network if their departure leads to the network becoming fragmented into disconnected segments. Similarly, certain Internet routers are considered critical to the functioning of the Internet, as their removal would result in the malfunctioning of systems.\n",
    "\n",
    "We can consider two types of network damage: random failure and target attack. In a random failure scenario, nodes are selected at random for removal. However, in a targeted attack, nodes are strategically chosen for removal based on specific criteria. For instance, nodes may be removed in the descending order of their degree centrality.\n",
    "\n",
    "\n",
    "## Random failure\n",
    "\n",
    "Let's break the network ðŸ˜ˆ! Before damaging the network, we should damage a copy of the network while keeping the original network as it is. This way, we can come back to the original network and compare it against the damaged one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_damaged = g.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014958c",
   "metadata": {},
   "source": [
    "To simulate random failures, we randomly sample some nodes and remove them from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of nodes to be removed\n",
    "n_nodes_removed = 10\n",
    "nodes_to_be_removed = np.random.choice(n_nodes, size=n_nodes_removed, replace=False)\n",
    "\n",
    "# Remove them from the network\n",
    "g_damaged.delete_vertices(nodes_to_be_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f360c8",
   "metadata": {},
   "source": [
    "If the removal of the nodes is substantial to the network, we expect to see the network to be fragmented into small connected components. To assess the connectivity of the network, one can measure the fraction of nodes in the giant component in all nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf27589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_connectivity(g_damaged, g):\n",
    "    # If the damaged network has no node left, return 0 connectivity\n",
    "    if g_damaged.vcount() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Find the connected components\n",
    "    component_membership = g_damaged.connected_components().membership\n",
    "\n",
    "    # Count the number of nodes in each component\n",
    "    n_nodes_comp = np.bincount(component_membership)\n",
    "\n",
    "    # Return the proportion of nodes in the giant component\n",
    "    return np.max(n_nodes_comp) / float(g.vcount())\n",
    "\n",
    "\n",
    "score_orig = eval_connectivity(g, g)\n",
    "score_damaged = eval_connectivity(g_damaged, g)\n",
    "print(score_orig, score_damaged)\n",
    "# n_connected_comp = len(g.components())\n",
    "# n_connected_comp_damaged = len(g_damaged.components())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad44cb1",
   "metadata": {},
   "source": [
    "A network is robust if the network does not break into small pieces if some nodes are removed. Let's test the robustness more systematically. We iteratively remove some number of nodes and see how fast/slow network connectivity drops. More specifically,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_damaged = g.copy()\n",
    "\n",
    "n_nodes_removed = 1\n",
    "n_nodes = g.vcount()  # Number of nodes\n",
    "\n",
    "results = []\n",
    "while g_damaged.vcount() > 0:  # Loop if the network has at least one nod\n",
    "    # Get the nodes in the network\n",
    "    nodes_in_networks = g_damaged.vs.indices\n",
    "\n",
    "    # Sample nodes to remove\n",
    "    nodes_removed = np.random.choice(\n",
    "        nodes_in_networks, size=np.minimum(n_nodes_removed, len(nodes_in_networks))\n",
    "    )\n",
    "\n",
    "    # Delete\n",
    "    g_damaged.delete_vertices(nodes_removed)\n",
    "\n",
    "    # Evaluate the network connectivity\n",
    "    score = eval_connectivity(g_damaged, g)\n",
    "\n",
    "    # Save the results\n",
    "    results += [\n",
    "        {\n",
    "            \"score\": score,\n",
    "            \"frac_nodes_removed\": 1 - g_damaged.vcount() / n_nodes,\n",
    "            \"attack\": \"random\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "plot_data = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax = sns.lineplot(data=plot_data, x=\"frac_nodes_removed\", y=\"score\")\n",
    "ax.set_xlabel(\"Proportion of nodes removed\")\n",
    "ax.set_ylabel(\"Proportion of nodes in a core\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873046f",
   "metadata": {},
   "source": [
    "### Targeted attack\n",
    "\n",
    "In a targeted attack, we will remove nodes based on some criteria. Let us demonstrate the idea by using the degree centrality. With the degree centrality, we will remove nodes with the highest degree in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_damaged = g.copy()\n",
    "\n",
    "n_nodes_removed = 1\n",
    "n_nodes = g.vcount()  # Number of nodes\n",
    "\n",
    "while g_damaged.vcount() > 0:  # Loop if the network has at least one nod\n",
    "    # Get the nodes in the network\n",
    "    nodes_in_networks = np.array(g_damaged.vs.indices)\n",
    "\n",
    "    # Get the degree centrality\n",
    "    deg = np.array(g_damaged.degree())\n",
    "\n",
    "    # Find the nodes with the highest degree.\n",
    "    nodes_removed = np.argsort(deg)[::-1][\n",
    "        : np.minimum(n_nodes_removed, len(nodes_in_networks))\n",
    "    ]\n",
    "\n",
    "    # Delete\n",
    "    g_damaged.delete_vertices(nodes_removed)\n",
    "\n",
    "    # Evaluate the network connectivity\n",
    "    score = eval_connectivity(g_damaged, g)\n",
    "\n",
    "    # Save the results\n",
    "    results += [\n",
    "        {\n",
    "            \"score\": score,\n",
    "            \"frac_nodes_removed\": 1 - g_damaged.vcount() / n_nodes,\n",
    "            \"attack\": \"targeted\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "plot_data = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax = sns.lineplot(data=plot_data, x=\"frac_nodes_removed\", y=\"score\", hue=\"attack\")\n",
    "ax.set_xlabel(\"Number of nodes removed\")\n",
    "ax.set_ylabel(\"Proportion of nodes in a core\")\n",
    "ax.legend(frameon=False)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441629f",
   "metadata": {},
   "source": [
    "The robustness profile curve provides insights into the network's resilience against random attacks and random closure of airports. While the network demonstrates robustness to such events, it is important to note that removing a small number of airports, particularly those with a high degree, can significantly impact the network.\n",
    "\n",
    "While the profile curve is informative, it is convenient to summarize the curve into a single number, called *$R$-index*. It is defined as the area under the robustness curve.\n",
    "\n",
    "$$\n",
    "R = \\frac{1}{N} \\sum_{x=1}^N y(x/N)\n",
    "$$\n",
    "where $y$ is the robustness at fraction $x/N$, and $N$ is the number of all nodes in the network. A higher value indicates that the network is robust against the attack. The $R$-index has a maximum value of 1/2 (i.e., which corresponds to a diagonal line in the plot above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.groupby(\"attack\").mean()[[\"score\"]]\n",
    "\n",
    "# Or alternatively\n",
    "for attack_type, df in plot_data.groupby(\"attack\"):\n",
    "    rindex = df[\"score\"].sum() / n_nodes\n",
    "    print(attack_type, \"%.3f\" % rindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5983eec",
   "metadata": {},
   "source": [
    "# Core Decomposition\n",
    "\n",
    "![](https://www.researchgate.net/publication/337008832/figure/fig1/AS:834053125206017@1575865169184/Example-of-the-k-core-decomposition.png)\n",
    "\n",
    "What if we remove nodes from a network in reverse order, starting with the small-degree nodes and moving toward the high-degree nodes? This approach, known as *$k$-core decomposition*, aims to iteratively remove unimportant nodes to identify the important nodes that survive throughout the removal process.\n",
    "\n",
    "The $k$-core is the maximal subgraph of a network consisting of nodes with degrees greater than or equal to $k$.\n",
    "There is a simple algorithm to identify them, which operates as follows:\n",
    "\n",
    "1. Calculate the degree of nodes in the network\n",
    "2. Remove the nodes with degree $k$ or less in the network.\n",
    "3. Recalculate the degree\n",
    "4. If all nodes have a degree less than $k$ in the removed network, terminate the algorithm. Otherwise, go back to step 2.\n",
    "\n",
    "Let's implement the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_core = g.copy()\n",
    "k = 20\n",
    "while True:\n",
    "    # Find nodes in the network\n",
    "    nodes_in_network = np.array(g_core.vs.indices)\n",
    "\n",
    "    # Calculate the degree\n",
    "    degree = np.array(g_core.degree())\n",
    "\n",
    "    # Find nodes with degree $k$ or less\n",
    "    nodes_to_remove = nodes_in_network[degree < k]\n",
    "\n",
    "    # If there is no node to remove, then terminate the algorithm.\n",
    "    if len(nodes_to_remove) == 0:\n",
    "        break\n",
    "\n",
    "    # Remove\n",
    "    g_core.delete_vertices(nodes_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41672c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_node_ids = g_core.vs()[\"node_id\"]\n",
    "\n",
    "core_node_table = node_table.iloc[core_node_ids]\n",
    "labels = core_node_table[\"Name\"].values\n",
    "\n",
    "node_color = core_node_table[\"region\"].values\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "cmap = {k: palette[i] for i, k in enumerate(set(node_color))}\n",
    "node_color = core_node_table[\"region\"].map(cmap)\n",
    "\n",
    "igraph.plot(\n",
    "    g_core,\n",
    "    vertex_label=labels,\n",
    "    vertex_size=10,\n",
    "    edge_width=0.1,\n",
    "    vertex_color=node_color,\n",
    "    layout=\"kk\",\n",
    "    bbox=(500, 500),\n",
    "    vertex_label_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b98768",
   "metadata": {},
   "source": [
    "$k$-core has many interesting properties.\n",
    "1. $k$-core is nested, meaning that $k$ core contains $k+1$ core.\n",
    "2. $k$-core sets the upper bounds for the density of edges and the diameter of the subgraph.\n",
    "3. $k$-core contains the largest cliques.\n",
    "\n",
    "$k$-core number of a node is the maximum $k$ that the node survives the node removal process. For instance, if a node has $k$-core number of 3, it means that it belongs to $1,2,3$-cores but does not belong to $4$-core and above. Thus, nodes with a high-core number are those that can be regarded as the important nodes in the network.\n",
    "\n",
    "With igraph, it is easy to find the $k$-core number, with a more efficient algorithm. So, we don't need to actually write the code to get it. But I hope you find it fun to see how it is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c37f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcore_number = g.coreness()\n",
    "\n",
    "# The above core can be generated by\n",
    "# g_cores = g.induced_subgraph(np.where(np.array(kcore_number)>=k)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69239e9e",
   "metadata": {},
   "source": [
    "Some useful tips about $k$-core decomposition.\n",
    "\n",
    "- $k$-core decomposition is a quite useful tool in practice to downsize the network. Many empirical networks are notoriously large, and it is often impossible to analyze with a given computing capacity at hand. A remedy is to focus on the $k$-core of the network since most edges are held by the nodes in the large-degree nodes. Since most nodes have a small degree in many empirical networks, using a moderately small $k$ can drastically reduce the size of the network.\n",
    "- The concept of the $k$-core is extended to the directed network: https://link.springer.com/article/10.1007/s10115-012-0539-0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b547d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c24dc",
   "metadata": {},
   "source": [
    "**Question 1: Which airport is the most central in terms of the closeness centrality? List the top 5 most central airports. You may use the APIs to compute the shortest path, but do not use built-in APIs that give the closeness centrality such as igraph.Graph.closeness**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b68e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code -------------------\n",
    "# Compute the centrality\n",
    "\n",
    "centrality = np.zeros(n_nodes)\n",
    "centrality = (\n",
    "    ...\n",
    ")  # Compute the closeness centrality of each node $i$ and set it to centrality[i].\n",
    "# -------------------\n",
    "\n",
    "# Check the correctness of the computed closeness\n",
    "assert np.all(np.isclose(centrality, g.closeness()))\n",
    "\n",
    "# Show the top K airport with the largst centrality\n",
    "topK = 5\n",
    "top_airport_ids = np.argsort(centrality)[::-1][:topK]\n",
    "node_table.iloc[top_airport_ids][[\"Name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2937a",
   "metadata": {},
   "source": [
    "**Question 2: Compute the betweenness centrality of the airports and show the top 5 airports. You may use APIs that directly compute the betweenness centrality, such as igraph.Graph.betweenness**.\n",
    "\n",
    "You should see an interesting airport that is not central in terms of the closeness centrality but is central in terms of the betweenness centrality. If you are curious why, here is a nice reading to understand why: https://toreopsahl.com/2011/08/12/why-anchorage-is-not-that-important-binary-ties-and-sample-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32c9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3269d34",
   "metadata": {},
   "source": [
    "**Question 3: Plot the robustness profile curve for the betweenness centrality, together with the curves for random attack and the target attack by the degree centrality. Compute the $R$-index for the betweenness centrality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5e437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d01b90b",
   "metadata": {},
   "source": [
    "**Question 4: Identify the airports with the highest k-core number and plot their subgraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code ------\n",
    "\n",
    "# Generate an igraph object g_core that consists of the nodes in the k-core of the largest k\n",
    "g_core = ...\n",
    "# ----------------\n",
    "\n",
    "# Run the following code to help us grade\n",
    "assert g_core.vcount() == 38"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnetsci",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
